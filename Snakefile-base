import pandas as pd
from snakemake.utils import validate
import sys
import time

shell.executable('bash')

# Import config
configfile: "config.yaml"

# Set working dir to "working/", you can change this to anything.
# The rationale is you can git clone the pipeline and run it without doing any juggling.
# Note that most things need to be prefixed with ../ to refer to the current directory,
# but there are exceptions like when reading cfg files and conda environments.
workdir: "working/"

onsuccess:
    # TODO Need to update https://github.com/slackapi/python-slackclient/wiki/Migrating-to-2.x
    cwd = os.getcwd()
    if config["slack_token"]:
        try:
            from slackclient import SlackClient

            token = config["slack_token"]
            sc = SlackClient(token)
            sc.api_call(
                    "chat.postMessage", channel=config["slack_channel"],
                    attachments= [{
                        "title": "Snakemake pipeline completed successfully",
                        "color": "#36a64f",
                        "text": "Hooray!",
                        "footer": "Completed pipeline spotted by SnakeEyes",
                        "footer_icon": "https://avatars.slack-edge.com/2019-05-07/627979128852_e1d616abbd7312343db8_512.png",
                        "ts": int(time.time()),
                        "fields": [
                            { "title": "Working Directory", "value": cwd, "short": False },
                        ],
                    }]
            )
        except ModuleNotFoundError:
            pass

onerror:
    cwd = os.getcwd()
    if config["slack_token"]:
        try:
            from slackclient import SlackClient

            token = config["slack_token"]
            sc = SlackClient(token)
            sc.api_call(
                    "chat.postMessage", channel=config["slack_channel"],
                    attachments= [{
                        "title": "Snakemake pipeline terminated unexpectedly",
                        "color": "#e20b00",
                        "text": "Boo :(",
                        "footer": "Trashed pipeline spotted by SnakeEyes",
                        "footer_icon": "https://avatars.slack-edge.com/2019-05-07/627979128852_e1d616abbd7312343db8_512.png",
                        "ts": int(time.time()),
                        "fields": [
                            { "title": "Working Directory", "value": cwd, "short": False },
                        ],
                    }]
            )
        except ModuleNotFoundError:
            pass

# Load manifest(s)
samples = pd.read_table("../manifest.cfg").set_index("uuid", drop=False)     # defines the assembly and polishing strategies
illumina_lookup = pd.read_table("../reads.cfg").set_index("ont", drop=False) # provides a lookup of short reads for polishing

# Utility functions
def unroll_assemblies(w, name, unroll=True):
    if not unroll:
        return [name]

    polishes = name.split(".")
    if len(polishes) == 0 or len(polishes[0]) == 0:
        return []

    end_polish = polishes[-1]
    end_polish_f = end_polish.split("-")
    end_iter = int(end_polish_f[-1])
    if (end_iter - 1) < 1:
        return [name] + unroll_assemblies(w, ".".join(polishes[:-1]))
    else:
        end_polish_f[-1] = str(end_iter-1)
        return [name] + unroll_assemblies(w, ".".join(polishes[:-1] + ["-".join(end_polish_f)]))

def enumerate_assemblies(w=None, suffix="", unroll=True, base_only=False):
    base_assemblies = []
    polished_assemblies = []
    for uuid in samples["uuid"]:
        for assembler in samples.loc[uuid]["assemblers"].split(","):
            base_assemblies.append( "%s.%s.ctg.cns%s" % (uuid, assembler, suffix) )
            if samples.loc[uuid]["poa"] != '-' and not base_only:
                unrolled = unroll_assemblies(w, samples.loc[uuid]["poa"], unroll=unroll)
                context = ['%s.%s.ctg.cns.%s%s' % (uuid, assembler, step, suffix) for step in unrolled]
                polished_assemblies.extend(context)
    return base_assemblies + polished_assemblies

for a in enumerate_assemblies(suffix=".fa"):
    sys.stderr.write("*\t%s\n" % a)

rule finish:
    input:
        stat="assembly_stats.txt",
        meta="assembly_md5size.txt",
        kraken="kraken_summary.bond.tsv",
        polished=enumerate_assemblies(unroll=False, suffix=".fa"),
        base_graphs=enumerate_assemblies(unroll=False, base_only=True, suffix=".gfa.svg")

def input_polish(w, name):
    if int(w.iteration) > 1:
        contigs = "%s.%s.ctg.cns.%s%s-%s-%d.fa" % (w.uuid, w.assembler, w.polishedprefix, name, w.readtype, int(w.iteration)-1)
    elif w.polishedprefix=="":
        contigs = "%s.%s.ctg.cns.fa" % (w.uuid, w.assembler)
    else:
        contigs = "%s.%s.ctg.cns.%sfa" % (w.uuid, w.assembler, w.polishedprefix)
    return contigs

def input_polish_racon(w):
    return input_polish(w, "racon")
def input_polish_medaka(w):
    return input_polish(w, "medaka")
def input_polish_pilon(w):
    return input_polish(w, "pilon")
def input_polish_dehumanizer(w):
    return input_polish(w, "dehumanizer")

def minimap2_mode(w):
    if w.readtype == "ont":
        mode = "map-ont"
    elif w.readtype == "ill":
        mode = "sr"
    return mode

def polish_reads_input(w):
    if w.readtype == "ont":
        reads = os.path.join(config["long_fq_root"], samples.loc[w.uuid]['reads'])
    elif w.readtype == "ill":
        reads = expand(os.path.join(config["short_fq_root"], "{fq}"), fq=[illumina_lookup.loc[ samples.loc[w.uuid]['reads'] ]["i1"], illumina_lookup.loc[ samples.loc[w.uuid]['reads'] ]["i2"]])
    return reads

rule polish_racon:
    input: contigs=input_polish_racon, reads=polish_reads_input
    params:
        mode=minimap2_mode,
        cuda="--cudapoa-batches 8 --cuda-banded-alignment" if config["cuda"] else "",
    output:
        "{uuid}.{assembler}.ctg.cns.{polishedprefix,.*}racon-{readtype,\w+}-{iteration,\d+}.fa"
    threads: 12
    shell:
        "minimap2 -t {threads} -x {params.mode} {input.contigs} {input.reads} > {output}.paf; racon -m 8 -x -6 -g -8 -w 500 -t {threads} {input.reads} {output}.paf {input.contigs} {params.cuda} > {output}"

rule polish_medaka:
    singularity: config["medaka_env"],
    input: contigs=input_polish_medaka, reads=polish_reads_input
    params:
        prefix=lambda w: w.uuid+'.'+w.assembler,
        model=lambda w: samples.loc[w.uuid]['medakamodel'],
        batch="-b 100" if config["cuda"] else "",
    output:
        "{uuid}.{assembler}.ctg.cns.{polishedprefix,.*}medaka-{readtype,\w+}-{iteration,\d+}.fa"
    threads: 12
    shell:
        "export TF_FORCE_GPU_ALLOW_GROWTH=true; rm -rf medaka-{params.prefix}/*; medaka_consensus -i {input.reads} -d {input.contigs} -o medaka-{params.prefix} -t {threads} -m {params.model} {params.batch}; mv medaka-{params.prefix}/consensus.fasta {output}"

rule download_dehumanizer_database:
    output:
        ok=touch(os.path.join(config["dehumanizer_database_root"], "dehuman.ok")),
        a=os.path.join(config["dehumanizer_database_root"], "GCA_000786075.2_hs38d1_genomic.fna.mmi"),
        b=os.path.join(config["dehumanizer_database_root"], "GCA_000001405.27_GRCh38.p12_genomic.fna.mmi"),
        c=os.path.join(config["dehumanizer_database_root"], "hla_gen.fasta.mmi"),
        manifest=os.path.join(config["dehumanizer_database_root"], "manifest.txt")
    shell:
        "bash ../scripts/download_dehumanizer_refs.sh %s" % config["dehumanizer_database_root"]

rule polish_dehumanizer:
    input:
        contigs=input_polish_dehumanizer,
        ok=os.path.join(config["dehumanizer_database_root"], "dehuman.ok"),
        manifest=os.path.join(config["dehumanizer_database_root"], "manifest.txt")
    output:
        "{uuid}.{assembler}.ctg.cns.{polishedprefix,.*}dehumanizer-{readtype,\w+}-{iteration,\d+}.fa"
    threads: 3
    shell:
        "dehumanize {input.manifest} {input.contigs} {output}"

rule download_pilon:
    output: "pilon-1.23.jar"
    shell: "wget https://github.com/broadinstitute/pilon/releases/download/v1.23/pilon-1.23.jar"

rule polish_pilon:
    input: contigs=input_polish_pilon, reads=polish_reads_input, pilon="pilon-1.23.jar"
    params:
        mode=minimap2_mode,
    output:
        polish="{uuid}.{assembler}.ctg.cns.{polishedprefix,.*}pilon-{readtype,\w+}-{iteration,\d+}.fa"
    threads: 12
    shell:
        "echo {input.reads}; minimap2 -t {threads} -ax {params.mode} {input.contigs} {input.reads} > {output}.sam; samtools sort {output}.sam -T {wildcards.uuid} -m 2G -@ {threads} -o {output}.bam; samtools index {output}.bam; java -Xmx16G -jar {input.pilon} --genome {input.contigs} --bam {output}.bam --outdir pilon-{wildcards.uuid}/; mv pilon-{wildcards.uuid}/pilon.fasta {output}"

rule summarise_assembly_stats:
    input:
        enumerate_assemblies(suffix=".fa")
    output:
        "assembly_stats.txt"
    shell:
        "for fa in {input}; do perl ../scripts/assembly-stats.pl $fa; done > {output}"

rule summarise_assembly_meta:
    input:
        enumerate_assemblies(suffix=".fa")
    output:
        "assembly_md5size.txt"
    shell:
        "for fa in {input}; do base=`basename $fa`; md5=`md5sum $fa | cut -f1 -d' '`; size=`du -Lh $fa | cut -f1`; echo \"$base,$size,$md5\"; done > {output}"

rule bond_summarise_kraken:
    input:
        "kraken_summary.tsv"
    output:
        "kraken_summary.bond.tsv"
    shell:
        "bond {input} ../manifest.cfg > {output}"

rule summarise_kraken:
    input:
        enumerate_assemblies(suffix=".fa.k2")
    output:
        "kraken_summary.tsv"
    shell:
        "python ../scripts/extracken2.py {input} > {output}"

rule download_kraken_database:
    output:
        ok=touch(os.path.join(config["kraken2_database_root"], "k2db.ok")),
        h=os.path.join(config["kraken2_database_root"], "hash.k2d"),
        o=os.path.join(config["kraken2_database_root"], "opts.k2d"),
        t=os.path.join(config["kraken2_database_root"], "taxo.k2d"),
    shell: "bash ../scripts/download_kraken2_db.sh %s" % config["kraken2_database_root"]

rule kraken:
    input:
        fa="{uuid}.{prefix}.fa", ok=os.path.join(config["kraken2_database_root"], "k2db.ok")
    output:
        out="{uuid}.{prefix}.fa.k2",
        rep="{uuid}.{prefix}.fa.k2r",
    threads: 8
    shell:
        "kraken2 --db %s --use-names -t {threads} --output {output.out} --report {output.rep} {input.fa}" % config["kraken2_database_root"]

def pick_assembler_version(assembler):
    lookup = {
        "wtdbg2": "bin/wtdbg2",
        "wtdbg2_2-4": "bin/wtdbg2_2-4",
    }
    return lookup[assembler]

def pick_wtdbg2_cns_version(assembler):
    lookup = {
        "wtdbg2": "bin/wtpoa-cns",
        "wtdbg2_2-4": "bin/wtpoa-cns_2-4",
    }
    return lookup[assembler]

rule wtdbg2_consensus:
    input:
        "{uuid}.{assembler}.ctg.lay.gz"
    output:
        "{uuid}.{assembler,wtdbg2[A-z0-9_-]*}.ctg.cns.fa"
    params:
        cnsbin=lambda w: pick_wtdbg2_cns_version(w.assembler)
    threads: 12
    shell:
        "{params.cnsbin} -f -i {input} -o {output} -t {threads}"

# new and improved version of this rule doesn't fucking nuke your input reads
rule subset_reads:
    input:
        os.path.join(config["long_fq_root"], "{fq}.fq.gz")
    output:
        os.path.join(config["long_fq_root"], "{fq}.subset.{ratio}.fq.gz")
    params:
        ratio=lambda w: float(w.ratio)/100
    shell:
        "seqtk sample {input} {params.ratio} | gzip -1 > {output}"

rule rmdup_reads:
    input:
        os.path.join(config["long_fq_root"], "{fq}.fq.gz")
    output:
        out=os.path.join(config["long_fq_root"], "{fq}.rmdup.fq.gz"),
        dup=os.path.join(config["long_fq_root"], "{fq}.dup.fq.gz"),
    shell:
        "zcat {input} | seqkit rmdup -s -i -m -o {output.out} -d {output.dup}"


rule install_wtdbg2:
    output:
        ok=touch("w2.ok"),
        d=directory("git/wtdbg2"),
        w2_bin_904f2b3="bin/wtdbg2",
        cns_bin_904f2b3="bin/wtpoa-cns",
        w2_bin_6a0691e="bin/wtdbg2_2-4",
        cns_bin_6a0691e="bin/wtpoa-cns_2-4"
    shell: "cd git; git clone https://github.com/ruanjue/wtdbg2.git; cd wtdbg2; git reset --hard 904f2b3ebdaa1e6f268cc58937767891a00d5bcb; make; cp wtdbg2 ../../bin; cp wtpoa-cns ../../bin; git reset --hard 6a0691e308b3644b6f718a03679f697d058e2be6; make; cp wtdbg2 ../../bin/wtdbg2_2-4; cp wtpoa-cns ../../bin/wtpoa-cns_2-4;"

rule wtdbg2_assembly:
    input:
        reads=lambda w: os.path.join(config["long_fq_root"], samples.loc[w.uuid]['reads']),
        ready="w2.ok"
    params:
        abin=lambda w: pick_assembler_version(w.assembler),
        prefix=lambda w: w.uuid+'.'+w.assembler,
        pmer=lambda w: samples.loc[w.uuid]['pmer'],
        kmer=lambda w: samples.loc[w.uuid]['kmer'],
        sampler=lambda w: samples.loc[w.uuid]['sampler'],
        edge=lambda w: samples.loc[w.uuid]['edge'],
        length=lambda w: samples.loc[w.uuid]['length'],
        max_k=lambda w: samples.loc[w.uuid]['max_k'],
        max_node=lambda w: samples.loc[w.uuid]['max_node'],
    output:
        lay="{uuid}.{assembler,wtdbg2}.ctg.lay.gz",
        dot="{uuid}.{assembler,wtdbg2}.ctg.dot.gz",
    threads: 24
    shell:
        "{params.abin} -f -i {input.reads} -o {params.prefix} -S {params.sampler} -e {params.edge} -k {params.kmer} -p {params.pmer} -L {params.length} -K {params.max_k} --node-max {params.max_node} -t {threads}"

rule wtdbg2_24_assembly:
    input:
        reads=lambda w: os.path.join(config["long_fq_root"], samples.loc[w.uuid]['reads']),
        ready="w2.ok"
    params:
        abin=lambda w: pick_assembler_version(w.assembler),
        prefix=lambda w: w.uuid+'.'+w.assembler,
        pmer=lambda w: samples.loc[w.uuid]['pmer'],
        kmer=lambda w: samples.loc[w.uuid]['kmer'],
        sampler=lambda w: samples.loc[w.uuid]['sampler'],
        edge=lambda w: samples.loc[w.uuid]['edge'],
        length=lambda w: samples.loc[w.uuid]['length'],
        max_k=lambda w: samples.loc[w.uuid]['max_k'],
        max_node=lambda w: samples.loc[w.uuid]['max_node'],
        genome_size=config["genome_size"],
    output:
        lay="{uuid}.{assembler,wtdbg2[A-z0-9_-]*}.ctg.lay.gz",
        dot="{uuid}.{assembler,wtdbg2[A-z0-9_-]*}.ctg.dot.gz",
    threads: 24
    shell:
        "{params.abin} -f -i {input.reads} -o {params.prefix} -S {params.sampler} -e {params.edge} -k {params.kmer} -p {params.pmer} -L {params.length} -t {threads} -K {params.max_k} --node-max {params.max_node} -X {params.max_k} -g {params.genome_size}"

rule install_flye:
    output:
        ok=touch("flye.ok"),
        d=directory("git/Flye"),
        flye_bin="bin/flye",
    shell: "cd git; git clone https://github.com/fenderglass/Flye.git; cd Flye; git reset --hard af246d6a942bbc57fe02049bee92645f43c87b62; make; cp bin/flye ../../bin;"

# TODO We need to use git/Flye/bin/flye as the script sets up some dir dependent stuff
rule flye_assembly:
    conda: "environments/flye.yaml"
    input:
        reads=lambda w: os.path.join(config["long_fq_root"], samples.loc[w.uuid]['reads']),
        ready="flye.ok"
    params:
        overlap=lambda w: '-m %s' % samples.loc[w.uuid]['flyem'] if samples.loc[w.uuid]['flyem'] != '-' else '',
        genome_size=config["genome_size"],
        d = "{uuid}.{assembler,flye[A-z0-9_-]*}/"
    output:
        fa = "{uuid}.{assembler,flye[A-z0-9_-]*}/assembly.fasta",
        gfa = "{uuid}.{assembler,flye[A-z0-9_-]*}/assembly_graph.gfa"
    threads: 24
    shell:
        "git/Flye/bin/flye --nano-raw {input.reads} --meta --plasmids -g {params.genome_size} -o {params.d} -t {threads} {params.overlap}"

rule link_flye_assembly:
    input: "{uuid}.{assembler}/assembly.fasta"
    output: "{uuid}.{assembler,flye[A-z0-9._-]*}.ctg.cns.fa"
    shell: "ln -s {input} {output}"

rule install_bandage_linux:
    output: ok=touch("bandage.ok"), b="ware/bandage/Bandage",
    shell: "cd ware; wget https://github.com/rrwick/Bandage/releases/download/v0.8.1/Bandage_Ubuntu_static_v0_8_1.zip; unzip Bandage_Ubuntu_static_v0_8_1.zip -d bandage;"

rule prep_wtdbg2_gfa:
    input:
        dot="{uuid}.{assembler,wtdbg2[A-z0-9_-]*}.ctg.dot.gz",
        assembly="{uuid}.{assembler,wtdbg2[A-z0-9_-]*}.ctg.lay.gz"
    output: "{uuid}.{assembler,wtdbg2[A-z0-9._-]*}.ctg.cns.gfa"
    shell: "zcat {input.dot} | perl git/wtdbg2/scripts/wtdbg-dot2gfa.pl > {output}"

#NOTE We reduce only the flye GFA because it has too many links to draw, and also the
# wtdbg2 graph isnt actually representative of the consensus so the contigs dont match up at all
rule prep_flye_gfa:
    input: "{uuid}.{assembler,flye[A-z0-9_-]*}/assembly_graph.gfa"
    output: "{uuid}.{assembler,flye[A-z0-9._-]*}.ctg.cns.gfa"
    shell: "python ../scripts/reduce_gfa.py {input} 50000 > {output}"

rule bandage_assembly:
    input:
        b="bandage.ok",
        gfa="{uuid}.{prefix}.gfa",
        assembly="{uuid}.{prefix}.fa"
    output: "{uuid}.{prefix}.gfa.svg"
    shell: "ware/bandage/Bandage image {input.gfa} {output}"
